# v0.7.0 Architecture: Multi-Provider AI Fallback

**Phase**: Block G & H (Opus + Sonnet implementation)
**Last Updated**: 2026-02-16
**Status**: Pre-Implementation Planning

---

## System Overview

```
┌─────────────────────────────────────────────────────────────┐
│                    Trispr Flow v0.7.0                       │
└─────────────────────────────────────────────────────────────┘
                              │
                    ┌─────────┴─────────┐
                    ▼                   ▼
          ┌──────────────────┐  ┌──────────────────┐
          │  Transcription   │  │ Post-Processing  │
          │  (Whisper/Vibe)  │  │ (Local Rules)    │
          └──────────────────┘  └──────────────────┘
                    │                   │
                    └─────────┬─────────┘
                              ▼
                    ┌──────────────────┐
                    │  AI Fallback     │ (NEW in v0.7.0)
                    │ (Optional Cloud) │
                    └──────┬───────────┘
                           ▼
                ┌──────────────────────────┐
                │ Provider Factory         │
                │ ┌────────────────────┐   │
                │ │ Claude Client      │   │
                │ │ OpenAI Client      │   │
                │ │ Gemini Client      │   │
                │ └────────────────────┘   │
                └──────────────────────────┘
                           │
        ┌──────────────────┼──────────────────┐
        ▼                  ▼                  ▼
    [Claude API]    [OpenAI API]        [Gemini API]
```

---

## Rust Architecture (Backend)

### Module Structure

```
src-tauri/src/
├── lib.rs (register new commands)
├── ai_fallback/
│   ├── mod.rs (module root)
│   ├── provider.rs (trait + factory)
│   ├── claude.rs (Claude client)
│   ├── openai.rs (OpenAI client)
│   ├── gemini.rs (Gemini client)
│   ├── models.rs (request/response types)
│   └── error.rs (unified error handling)
├── state.rs (updated Settings schema)
└── [existing modules]
```

### Provider Trait (Core Abstraction)

```rust
pub trait AIProvider: Send + Sync {
    fn name(&self) -> &'static str;

    async fn refine_transcript(
        &self,
        transcript: &str,
        prompt: &str,
        options: RefinementOptions,
    ) -> Result<RefinementResult, AIError>;

    fn estimate_cost(&self, input_tokens: usize, output_tokens: usize) -> f64;
    fn available_models(&self) -> Vec<&'static str>;
}

pub struct RefinementOptions {
    pub temperature: f32,
    pub max_tokens: usize,
    pub language: Option<String>,
}

pub struct RefinementResult {
    pub text: String,
    pub usage: TokenUsage,
    pub provider: String,
    pub model: String,
}

pub struct TokenUsage {
    pub input_tokens: usize,
    pub output_tokens: usize,
    pub total_cost_usd: f64,
}
```

### Provider Factory

```rust
pub struct ProviderFactory;

impl ProviderFactory {
    pub async fn create(config: &AIFallbackConfig) -> Result<Box<dyn AIProvider>, AIError> {
        match config.provider.as_str() {
            "claude" => Ok(Box::new(ClaudeProvider::new(&config.api_key)?)),
            "openai" => Ok(Box::new(OpenAIProvider::new(&config.api_key)?)),
            "gemini" => Ok(Box::new(GeminiProvider::new(&config.api_key)?)),
            _ => Err(AIError::UnknownProvider(config.provider.clone())),
        }
    }
}
```

### Tauri Commands (New)

```rust
#[tauri::command]
async fn refine_transcript(
    state: tauri::State<'_, AppState>,
    transcript: String,
) -> Result<RefinementResult, String> {
    // 1. Check if AI fallback enabled
    // 2. Load provider from factory
    // 3. Call refine_transcript
    // 4. Return result + cost estimate
}

#[tauri::command]
async fn test_provider_connection(
    provider: String,
    api_key: String,
) -> Result<bool, String> {
    // Validate API key by making test request
}

#[tauri::command]
async fn fetch_available_models(
    provider: String,
    api_key: String,
) -> Result<Vec<String>, String> {
    // List models available for provider
}
```

---

## Settings Schema (Updated)

### Type Definitions (Rust)

```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AIFallbackSettings {
    pub enabled: bool,
    pub provider: String,  // "claude" | "openai" | "gemini"
    pub model: String,
    pub api_key: String,   // TODO: Move to keyring
    pub temperature: f32,  // 0.0-1.0
    pub max_tokens: usize,
    pub custom_prompt_enabled: bool,
    pub custom_prompt: Option<String>,
    pub use_default_prompt: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Settings {
    // ... existing fields ...
    pub ai_fallback: AIFallbackSettings,
}
```

### Settings Migration

```rust
fn migrate_cloud_fallback_to_ai_fallback(old: &Value) -> AIFallbackSettings {
    if let Some(enabled) = old.get("cloud_fallback_enabled").and_then(|v| v.as_bool()) {
        if enabled {
            if let Some(key) = old.get("claude_api_key").and_then(|v| v.as_str()) {
                // Migrate to keyring (Windows/macOS)
                #[cfg(target_os = "windows")]
                store_in_credential_manager("trispr-flow/claude", key).ok();

                #[cfg(target_os = "macos")]
                store_in_keychain("trispr-flow/claude", key).ok();

                return AIFallbackSettings {
                    enabled: true,
                    provider: "claude".to_string(),
                    model: "claude-3-5-sonnet-20241022".to_string(),
                    api_key: key.to_string(),
                    temperature: 0.3,
                    max_tokens: 4000,
                    custom_prompt_enabled: false,
                    custom_prompt: None,
                    use_default_prompt: true,
                };
            }
        }
    }
    AIFallbackSettings::default()
}
```

---

## TypeScript Frontend Architecture

### Type Definitions

```typescript
// types.ts - Add to Settings interface
interface AIFallbackSettings {
  enabled: boolean;
  provider: 'claude' | 'openai' | 'gemini';
  model: string;
  temperature: number;
  maxTokens: number;
  customPromptEnabled: boolean;
  customPrompt?: string;
  useDefaultPrompt: boolean;
}

interface RefinementResult {
  text: string;
  provider: string;
  model: string;
  tokensUsed: {
    input: number;
    output: number;
  };
  costUSD: number;
  executionTimeMs: number;
}
```

### UI Components

```typescript
// ai-fallback.ts (new module)
export interface AIFallbackUI {
  renderExpander(): HTMLElement;
  wireEvents(): void;
  updateProviderModels(provider: string): Promise<void>;
  showApiKeySetup(provider: string): Promise<void>;
  showCustomPromptEditor(): Promise<void>;
}
```

### Event Flow

```
User enables AI Fallback
  ↓
Show provider selector
  ↓
User selects provider (Claude/OpenAI/Gemini)
  ↓
Show API key setup dialog
  ↓
User pastes API key
  ↓
Click "Test Connection" → calls test_provider_connection
  ↓
Fetch available models → populate model dropdown
  ↓
User selects model
  ↓
Settings saved to settings.json
```

---

## Data Flow: Transcription to Refinement

```
1. User records mic/system audio
2. Whisper transcribes → raw text
3. If Post-Processing enabled:
   - Apply local rules (punctuation, numbers, vocabulary)
4. If AI Fallback enabled:
   - Get selected provider + model + prompt
   - Invoke Tauri command: refine_transcript(text)
   - Wait for AI response (5-30s depending on text length)
   - Show cost estimate: "$0.01 estimated cost"
   - Update history with refined text
5. Ready for export/paste/search

Example cost estimation:
- Input: 500 tokens
- Output: 200 tokens
- Provider: OpenAI (GPT-4o)
- Cost: (500 * $0.005 + 200 * $0.015) / 1000 = $0.005
```

---

## Error Handling Strategy

### Error Types

```rust
pub enum AIError {
    // Authentication
    InvalidApiKey,
    ApiKeyNotFound,

    // Rate limiting
    RateLimitExceeded { retry_after_seconds: u64 },
    QuotaExceeded,

    // Input validation
    TextTooLong { max_tokens: usize, provided_tokens: usize },
    InvalidPrompt(String),

    // Network/API
    NetworkError(String),
    ProviderUnavailable(String),
    UnexpectedResponse(String),

    // Configuration
    UnknownProvider(String),
    InvalidModel(String),
}
```

### User-Facing Errors

| Error | Message | Action |
|-------|---------|--------|
| InvalidApiKey | "Invalid API key. Check your key in Settings." | Show API key setup |
| RateLimitExceeded | "Rate limit reached. Retry in {N}s." | Disable button for N seconds |
| TextTooLong | "Transcript too long for AI refinement. Max {N} tokens." | Fall back to local rules |
| ProviderUnavailable | "Claude API currently unavailable. Using original text." | Toast + continue |
| NetworkError | "Network error. Check your connection." | Retry button |

---

## Performance Considerations

### Latency Budget

| Operation | Target | Notes |
|-----------|--------|-------|
| Test Connection | <2s | User clicks "Test", sees result immediately |
| Fetch Models | <2s | Called on provider selection |
| Refine Transcript | 5-30s | Depends on text length, network, provider |
| UI Response | <100ms | All UI interactions should be instant |

### Optimization Strategies

1. **Streaming**: Show refinement as it arrives (for long texts)
2. **Caching**: Cache model lists (valid for 24h)
3. **Async**: Non-blocking UI during refinement
4. **Cancellation**: Allow user to cancel in-flight requests

---

## Security Considerations

### API Key Management

**Windows (Priority 1)**:
```rust
use dpapi::encrypt;

fn store_api_key(provider: &str, key: &str) -> Result<()> {
    let encrypted = windows::Win32::Security::Cryptography::encrypt(&key.as_bytes())?;
    fs::write(
        app_data_dir()?.join(format!("{}_key.bin", provider)),
        encrypted,
    )?;
    Ok(())
}
```

**macOS (Priority 2)**:
```rust
use security_framework::item::SearchOptions;

fn store_in_keychain(provider: &str, key: &str) -> Result<()> {
    // Use macOS Keychain
}
```

**Linux/Fallback**:
```json
// settings.json with warning
{
  "ai_fallback": {
    "api_key_stored": "file",
    "_warning": "API key stored in plain text. Run: chmod 600 ~/.config/trispr-flow/settings.json"
  }
}
```

### Data Privacy

- API keys never logged
- Transcript sent only to user's chosen provider (not to Anthropic/OpenAI/Google unless user selected)
- Cost estimates calculated locally (no API call)
- User controls whether refinement is enabled/disabled

---

## Testing Strategy (Block H - Task 38)

### Unit Tests

```rust
#[cfg(test)]
mod tests {
    #[test]
    fn test_provider_factory_creates_claude() { }

    #[test]
    fn test_invalid_api_key_error() { }

    #[test]
    fn test_cost_estimation_accuracy() { }

    #[test]
    fn test_settings_migration_cloud_fallback_to_ai_fallback() { }
}
```

### E2E Tests

```typescript
// e2e: ai-fallback.test.ts
describe("AI Fallback E2E", () => {
  test("Claude refinement: raw → refined", async () => {
    // 1. Record transcript
    // 2. Enable AI Fallback (Claude)
    // 3. Click "Refine"
    // 4. Verify output quality
    // 5. Check cost estimate displayed
  });

  test("OpenAI refinement workflow", async () => { });
  test("Gemini refinement workflow", async () => { });
  test("Error: invalid API key", async () => { });
  test("Error: rate limit", async () => { });
});
```

---

## Migration Path (v0.6.0 → v0.7.0)

### Breaking Changes
- `cloud_fallback_enabled` → `ai_fallback.enabled`
- `claude_api_key` → moved to system keyring (or settings.json with migration warning)
- Hard-coded prompt → user-editable with defaults

### Non-Breaking Changes
- New expander in existing Post-Processing panel
- New commands (refine_transcript, test_provider_connection)
- New Settings struct fields (backward compatible with defaults)

### User Migration
1. User upgrades to v0.7.0
2. Settings auto-migrated (Claude key moved to keyring)
3. AI Fallback disabled by default (user must re-enable)
4. First-time users: No existing keys, clean setup

---

## Dependencies

### New Rust Crates

```toml
# AI provider libraries
reqwest = { version = "0.11", features = ["json", "stream"] }  # HTTP client
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Key storage
[target.'cfg(target_os = "windows")'.dependencies]
windows = { version = "0.51", features = ["Win32_Security_Cryptography"] }

[target.'cfg(target_os = "macos")'.dependencies]
security-framework = "2.9"
```

### TypeScript (No new dependencies, use fetch API)

---

## Next Steps

**Block G (Opus)**:
1. Implement provider trait + factory
2. Implement settings migration
3. Build UI components
4. Add Tauri commands

**Block H (Sonnet)**:
1. Implement Claude client
2. Implement OpenAI client
3. Implement Gemini client
4. Add E2E tests

---

## References

- Current implementation: `src-tauri/src/cloud_fallback.rs` (to be refactored)
- Provider APIs:
  - Claude: https://docs.anthropic.com/
  - OpenAI: https://platform.openai.com/docs/
  - Gemini: https://ai.google.dev/

---

**Phase**: Pre-Implementation (Block F complete, ready for Block G)
**Status**: Architecture locked, ready for Opus sprint
